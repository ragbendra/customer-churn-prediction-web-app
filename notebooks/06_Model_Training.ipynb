{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Model Training\n",
    "\n",
    "**Objective**: Train and tune churn prediction models\n",
    "\n",
    "**Models**:\n",
    "- Logistic Regression (interpretable)\n",
    "- XGBoost (performance)\n",
    "- LightGBM (performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print('Libraries loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "MODEL_INPUT_PATH = Path('../data/05_model_input')\n",
    "MODEL_PATH = Path('../data/06_models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(MODEL_INPUT_PATH / 'selected_train.csv')\n",
    "\n",
    "TARGET = 'Churn'\n",
    "with open(MODEL_PATH / 'feature_list.json', 'r') as f:\n",
    "    FEATURES = json.load(f)\n",
    "\n",
    "print(f\"Features: {len(FEATURES)}\")\n",
    "print(f\"Samples: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train-Test Split (70/15/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 50/50 of temp = 15/15 of total\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\" DATA SPLIT:\")\n",
    "print(f\"Train: {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Val:   {len(X_val):,} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n CHURN RATES:\")\n",
    "print(f\"Train: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Val:   {y_val.mean()*100:.2f}%\")\n",
    "print(f\"Test:  {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SMOTE on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to training data only\n",
    "smote = SMOTE(sampling_strategy=0.6, random_state=42, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Before SMOTE: {len(X_train):,} samples\")\n",
    "print(f\"After SMOTE:  {len(X_train_smote):,} samples\")\n",
    "print(f\"New churn rate: {y_train_smote.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, MODEL_PATH / 'scaler.pkl')\n",
    "print(\" Saved: scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: Logistic Regression (Interpretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Training Logistic Regression...\")\n",
    "\n",
    "# Hyperparameter grid\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lr_search = GridSearchCV(\n",
    "    lr, lr_params, cv=cv, scoring='average_precision', n_jobs=-1, verbose=1\n",
    ")\n",
    "lr_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "lr_best = lr_search.best_estimator_\n",
    "print(f\"\\n Best params: {lr_search.best_params_}\")\n",
    "print(f\" Best CV AUC-PR: {lr_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation\n",
    "lr_proba = lr_best.predict_proba(X_val_scaled)[:, 1]\n",
    "lr_val_auc = roc_auc_score(y_val, lr_proba)\n",
    "lr_val_pr = average_precision_score(y_val, lr_proba)\n",
    "\n",
    "print(f\"Validation ROC-AUC: {lr_val_auc:.4f}\")\n",
    "print(f\"Validation PR-AUC:  {lr_val_pr:.4f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_best, MODEL_PATH / 'logistic_regression.pkl')\n",
    "print(\"\\n Saved: logistic_regression.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: XGBoost (Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Training XGBoost...\")\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "scale_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'scale_pos_weight': [1, scale_weight]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='aucpr', use_label_encoder=False)\n",
    "\n",
    "xgb_search = GridSearchCV(\n",
    "    xgb, xgb_params, cv=cv, scoring='average_precision', n_jobs=-1, verbose=1\n",
    ")\n",
    "xgb_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "print(f\"\\n Best params: {xgb_search.best_params_}\")\n",
    "print(f\" Best CV AUC-PR: {xgb_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation\n",
    "xgb_proba = xgb_best.predict_proba(X_val)[:, 1]\n",
    "xgb_val_auc = roc_auc_score(y_val, xgb_proba)\n",
    "xgb_val_pr = average_precision_score(y_val, xgb_proba)\n",
    "\n",
    "print(f\"Validation ROC-AUC: {xgb_val_auc:.4f}\")\n",
    "print(f\"Validation PR-AUC:  {xgb_val_pr:.4f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(xgb_best, MODEL_PATH / 'xgboost.pkl')\n",
    "print(\"\\n Saved: xgboost.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 3: LightGBM (Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Training LightGBM...\")\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'max_depth': [5, 10, -1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "lgb = LGBMClassifier(random_state=42, verbosity=-1)\n",
    "\n",
    "lgb_search = GridSearchCV(\n",
    "    lgb, lgb_params, cv=cv, scoring='average_precision', n_jobs=-1, verbose=1\n",
    ")\n",
    "lgb_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "lgb_best = lgb_search.best_estimator_\n",
    "print(f\"\\n Best params: {lgb_search.best_params_}\")\n",
    "print(f\" Best CV AUC-PR: {lgb_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation\n",
    "lgb_proba = lgb_best.predict_proba(X_val)[:, 1]\n",
    "lgb_val_auc = roc_auc_score(y_val, lgb_proba)\n",
    "lgb_val_pr = average_precision_score(y_val, lgb_proba)\n",
    "\n",
    "print(f\"Validation ROC-AUC: {lgb_val_auc:.4f}\")\n",
    "print(f\"Validation PR-AUC:  {lgb_val_pr:.4f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(lgb_best, MODEL_PATH / 'lightgbm.pkl')\n",
    "print(\"\\n Saved: lightgbm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'XGBoost', 'LightGBM'],\n",
    "    'CV_AUC_PR': [lr_search.best_score_, xgb_search.best_score_, lgb_search.best_score_],\n",
    "    'Val_ROC_AUC': [lr_val_auc, xgb_val_auc, lgb_val_auc],\n",
    "    'Val_PR_AUC': [lr_val_pr, xgb_val_pr, lgb_val_pr]\n",
    "})\n",
    "\n",
    "print(\" MODEL COMPARISON:\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select champion model (best PR-AUC)\n",
    "champion_idx = results['Val_PR_AUC'].idxmax()\n",
    "champion_name = results.loc[champion_idx, 'Model']\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': lr_best,\n",
    "    'XGBoost': xgb_best,\n",
    "    'LightGBM': lgb_best\n",
    "}\n",
    "\n",
    "champion_model = models[champion_name]\n",
    "\n",
    "print(f\"\\n CHAMPION MODEL: {champion_name}\")\n",
    "print(f\"   PR-AUC: {results.loc[champion_idx, 'Val_PR_AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Training Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save champion model\n",
    "joblib.dump(champion_model, MODEL_PATH / 'champion_model.pkl')\n",
    "\n",
    "# Save test set for evaluation\n",
    "test_data = pd.DataFrame(X_test, columns=FEATURES)\n",
    "test_data[TARGET] = y_test.values\n",
    "test_data.to_csv(MODEL_PATH / 'test_set.csv', index=False)\n",
    "\n",
    "# Save results\n",
    "results.to_csv(MODEL_PATH / 'training_results.csv', index=False)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'champion_model': champion_name,\n",
    "    'train_samples': len(X_train),\n",
    "    'train_samples_smote': len(X_train_smote),\n",
    "    'features': len(FEATURES),\n",
    "    'trained_at': datetime.now().isoformat()\n",
    "}\n",
    "with open(MODEL_PATH / 'training_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\" Saved:\")\n",
    "print(f\"   - champion_model.pkl ({champion_name})\")\n",
    "print(f\"   - test_set.csv\")\n",
    "print(f\"   - training_results.csv\")\n",
    "print(f\"   - training_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n Champion: {champion_name}\")\n",
    "print(\"\\n NEXT: Proceed to 07_Evaluation.ipynb\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}