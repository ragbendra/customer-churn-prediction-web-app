{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Feature Selection\n",
    "\n",
    "**Objective**: Select optimal 25-30 features for modeling\n",
    "\n",
    "**Methods**:\n",
    "1. Variance filter\n",
    "2. Correlation filter (r > 0.85)\n",
    "3. Mutual Information scores\n",
    "4. RFE with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print('Libraries loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "FEATURE_PATH = Path('../data/04_feature')\n",
    "MODEL_INPUT_PATH = Path('../data/05_model_input')\n",
    "MODEL_PATH = Path('../data/06_models')\n",
    "REPORTING_PATH = Path('../data/08_reporting')\n",
    "\n",
    "for p in [MODEL_INPUT_PATH, MODEL_PATH, REPORTING_PATH]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv(FEATURE_PATH / 'engineered_train.csv')\n",
    "df_holdout = pd.read_csv(FEATURE_PATH / 'engineered_holdout.csv')\n",
    "\n",
    "TARGET = 'Churn'\n",
    "feature_cols = [c for c in df_train.columns if c != TARGET]\n",
    "\n",
    "print(f\"Initial features: {len(feature_cols)}\")\n",
    "print(f\"Train samples: {len(df_train):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[feature_cols]\n",
    "y = df_train[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variance Filter (Remove < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for fair variance comparison\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Variance threshold\n",
    "var_threshold = 0.01\n",
    "selector = VarianceThreshold(threshold=var_threshold)\n",
    "selector.fit(X_scaled)\n",
    "\n",
    "# Get low variance features\n",
    "low_var_mask = ~selector.get_support()\n",
    "low_var_features = X.columns[low_var_mask].tolist()\n",
    "\n",
    "print(f\" Low variance features (< {var_threshold}): {len(low_var_features)}\")\n",
    "for f in low_var_features:\n",
    "    print(f\"   - {f}: variance = {X_scaled[f].var():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low variance features\n",
    "features_after_var = [c for c in feature_cols if c not in low_var_features]\n",
    "print(f\"\\n Features after variance filter: {len(features_after_var)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Filter (Drop from pairs r > 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, features, target, threshold=0.85):\n",
    "    \"\"\"Remove highly correlated features, keeping the one with higher target correlation.\"\"\"\n",
    "    X_subset = df[features]\n",
    "    corr_matrix = X_subset.corr().abs()\n",
    "    \n",
    "    # Get target correlations\n",
    "    target_corr = df[features].corrwith(df[target]).abs()\n",
    "    \n",
    "    # Find highly correlated pairs\n",
    "    to_drop = set()\n",
    "    drop_log = []\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if corr_matrix.iloc[i, j] > threshold:\n",
    "                feat1, feat2 = corr_matrix.columns[i], corr_matrix.columns[j]\n",
    "                \n",
    "                # Drop the one with lower target correlation\n",
    "                if target_corr[feat1] < target_corr[feat2]:\n",
    "                    to_drop.add(feat1)\n",
    "                    drop_log.append(f\"Dropped {feat1} (r={corr_matrix.iloc[i,j]:.2f} with {feat2})\")\n",
    "                else:\n",
    "                    to_drop.add(feat2)\n",
    "                    drop_log.append(f\"Dropped {feat2} (r={corr_matrix.iloc[i,j]:.2f} with {feat1})\")\n",
    "    \n",
    "    features_kept = [f for f in features if f not in to_drop]\n",
    "    return features_kept, list(to_drop), drop_log\n",
    "\n",
    "features_after_corr, dropped_corr, drop_log = remove_correlated_features(\n",
    "    df_train, features_after_var, TARGET, threshold=0.85\n",
    ")\n",
    "\n",
    "print(f\" Dropped for high correlation: {len(dropped_corr)}\")\n",
    "for log in drop_log[:10]:\n",
    "    print(f\"   {log}\")\n",
    "if len(drop_log) > 10:\n",
    "    print(f\"   ... and {len(drop_log)-10} more\")\n",
    "    \n",
    "print(f\"\\n Features after correlation filter: {len(features_after_corr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mutual Information Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mutual Information scores\n",
    "X_mi = df_train[features_after_corr].fillna(0)\n",
    "\n",
    "mi_scores = mutual_info_classif(X_mi, y, random_state=42)\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': features_after_corr,\n",
    "    'MI_Score': mi_scores\n",
    "}).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "print(\" TOP 20 FEATURES BY MUTUAL INFORMATION:\")\n",
    "display(mi_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MI scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "mi_df.head(25).sort_values('MI_Score').plot(\n",
    "    kind='barh', x='Feature', y='MI_Score',\n",
    "    color='#3498db', edgecolor='black', legend=False\n",
    ")\n",
    "plt.title('Top 25 Features by Mutual Information', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTING_PATH / 'mi_scores.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to top 40 by MI for RFE\n",
    "top_mi_features = mi_df.head(40)['Feature'].tolist()\n",
    "print(f\"\\n Top 40 MI features selected for RFE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for RFE\n",
    "X_rfe = df_train[top_mi_features].fillna(0)\n",
    "X_rfe_scaled = StandardScaler().fit_transform(X_rfe)\n",
    "\n",
    "# RFE with Cross-Validation\n",
    "estimator = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Running RFECV (this may take a few minutes)...\")\n",
    "rfecv = RFECV(\n",
    "    estimator=estimator,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    min_features_to_select=15,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_rfe_scaled, y)\n",
    "\n",
    "print(f\"\\n Optimal number of features: {rfecv.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV results\n",
    "selected_mask = rfecv.support_\n",
    "selected_features = [f for f, s in zip(top_mi_features, selected_mask) if s]\n",
    "\n",
    "print(f\" SELECTED FEATURES ({len(selected_features)}):\")\n",
    "for f in selected_features:\n",
    "    print(f\"    {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RFE results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(rfecv.min_features_to_select, len(rfecv.cv_results_['mean_test_score']) + rfecv.min_features_to_select), \n",
    "         rfecv.cv_results_['mean_test_score'], marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cross-Validation AUC-ROC')\n",
    "plt.title('RFE Feature Selection', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=rfecv.n_features_, color='r', linestyle='--', label=f'Optimal: {rfecv.n_features_}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTING_PATH / 'rfe_curve.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile final feature list (ensure 25-30 features)\n",
    "final_features = selected_features.copy()\n",
    "\n",
    "# If less than 25, add more from MI ranking\n",
    "if len(final_features) < 25:\n",
    "    additional = [f for f in top_mi_features if f not in final_features][:25-len(final_features)]\n",
    "    final_features.extend(additional)\n",
    "\n",
    "# If more than 30, trim\n",
    "final_features = final_features[:30]\n",
    "\n",
    "print(f\" FINAL SELECTED FEATURES ({len(final_features)}):\")\n",
    "print(\"=\"*60)\n",
    "for i, f in enumerate(final_features, 1):\n",
    "    mi_score = mi_df[mi_df['Feature'] == f]['MI_Score'].values\n",
    "    mi = mi_score[0] if len(mi_score) > 0 else 0\n",
    "    print(f\"{i:2d}. {f:<35} (MI: {mi:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final datasets with selected features\n",
    "X_train_final = df_train[final_features + [TARGET]]\n",
    "X_holdout_final = df_holdout[final_features]\n",
    "\n",
    "# Save\n",
    "X_train_final.to_csv(MODEL_INPUT_PATH / 'selected_train.csv', index=False)\n",
    "X_holdout_final.to_csv(MODEL_INPUT_PATH / 'selected_holdout.csv', index=False)\n",
    "\n",
    "# Save feature list as JSON\n",
    "with open(MODEL_PATH / 'feature_list.json', 'w') as f:\n",
    "    json.dump(final_features, f, indent=2)\n",
    "\n",
    "print(\" Saved:\")\n",
    "print(f\"   - {MODEL_INPUT_PATH / 'selected_train.csv'}\")\n",
    "print(f\"   - {MODEL_INPUT_PATH / 'selected_holdout.csv'}\")\n",
    "print(f\"   - {MODEL_PATH / 'feature_list.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Initial features: {len(feature_cols)}\")\n",
    "print(f\"After variance filter: {len(features_after_var)} (dropped {len(low_var_features)})\")\n",
    "print(f\"After correlation filter: {len(features_after_corr)} (dropped {len(dropped_corr)})\")\n",
    "print(f\"After RFECV: {len(final_features)}\")\n",
    "print(\"\\n NEXT: Proceed to 06_Model_Training.ipynb\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}